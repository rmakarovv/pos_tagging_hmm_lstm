{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "    Author: Roman Makarov\n",
        "    e-mail: mcronomus@gmail.com"
      ],
      "metadata": {
        "id": "ftRvhs6leHmN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hidden Markov Models for POS Tagging"
      ],
      "metadata": {
        "id": "7o7l16MVh2cH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data preparation"
      ],
      "metadata": {
        "id": "Z3JRxir55_Ff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/Gci04/AML-DS-2021/main/data/PosTagging/train_pos.txt\n",
        "!wget https://raw.githubusercontent.com/Gci04/AML-DS-2021/main/data/PosTagging/test_pos.txt"
      ],
      "metadata": {
        "id": "qbubruW7ydGo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "587ca181-28ae-4be1-accb-25b56e154414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-29 14:26:01--  https://raw.githubusercontent.com/Gci04/AML-DS-2021/main/data/PosTagging/train_pos.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1855828 (1.8M) [text/plain]\n",
            "Saving to: ‘train_pos.txt’\n",
            "\n",
            "train_pos.txt       100%[===================>]   1.77M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2023-05-29 14:26:02 (31.8 MB/s) - ‘train_pos.txt’ saved [1855828/1855828]\n",
            "\n",
            "--2023-05-29 14:26:02--  https://raw.githubusercontent.com/Gci04/AML-DS-2021/main/data/PosTagging/test_pos.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 418682 (409K) [text/plain]\n",
            "Saving to: ‘test_pos.txt’\n",
            "\n",
            "test_pos.txt        100%[===================>] 408.87K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-05-29 14:26:02 (11.3 MB/s) - ‘test_pos.txt’ saved [418682/418682]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "tags = []\n",
        "words = []\n",
        "tagged_sentences = []\n",
        "\n",
        "for line in open('train_pos.txt', 'r').readlines():\n",
        "    vals = tuple(line.strip().split())\n",
        "    try:\n",
        "        words.append(vals[0])\n",
        "        tags.append(vals[1])\n",
        "        tagged_sentences.append(vals)\n",
        "    except:\n",
        "        pass"
      ],
      "metadata": {
        "id": "PCwdSXg0QAeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences = [[]]\n",
        "for entry in tagged_sentences:\n",
        "    train_sentences[-1].append(entry)\n",
        "    if entry[0] == '.':\n",
        "        train_sentences.append([])"
      ],
      "metadata": {
        "id": "TUJy526TJxIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "test_sentences = [[]]\n",
        "\n",
        "for line in open('test_pos.txt', 'r').readlines():\n",
        "    if line.strip() == '':\n",
        "        continue\n",
        "\n",
        "    vals = tuple(line.strip().split())\n",
        "    try:\n",
        "        test_sentences[-1].append(vals)\n",
        "        if vals[0] == '.':\n",
        "            test_sentences.append([])\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "test_sentences.pop()"
      ],
      "metadata": {
        "id": "PVSRTEUR3z62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b826c85a-02cd-40a5-9a59-aa12050fec47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Map tag to some number\n",
        "tag_to_num = {}\n",
        "for tag in tags:\n",
        "    if tag not in tag_to_num:\n",
        "        tag_to_num[tag] = len(tag_to_num)\n",
        "\n",
        "# Map word to some number\n",
        "word_to_num = {'<UNK>': 0}\n",
        "for word in words:\n",
        "    if word not in word_to_num:\n",
        "        word_to_num[word] = len(word_to_num)"
      ],
      "metadata": {
        "id": "cEJNFoLb313O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Viterbi algorithnm"
      ],
      "metadata": {
        "id": "Y3vBG0zp6DlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def viterbi(y, A, B, Pi=None):\n",
        "    # Cardinality of the state space\n",
        "    K = A.shape[0]\n",
        "    # Initialize the priors with default (uniform dist) if not given by caller\n",
        "    Pi = Pi if Pi is not None else np.full(K, 1 / K)\n",
        "    T = len(y)\n",
        "    T1 = np.empty((K, T), 'd')\n",
        "    T2 = np.empty((K, T), 'B')\n",
        "\n",
        "    # Initilaize the tracking tables from first observation\n",
        "    T1[:, 0] = Pi * B[:, y[0]]\n",
        "    T2[:, 0] = 0\n",
        "\n",
        "    # Iterate throught the observations updating the tracking tables\n",
        "    for i in range(1, T):\n",
        "        T1[:, i] = np.max(T1[:, i - 1] * A.T * B[np.newaxis, :, y[i]].T, 1)\n",
        "        T2[:, i] = np.argmax(T1[:, i - 1] * A.T, 1)\n",
        "\n",
        "    # Build the output, optimal model trajectory\n",
        "    x = np.empty(T, 'B')\n",
        "    x[-1] = np.argmax(T1[:, T - 1])\n",
        "    for i in reversed(range(1, T)):\n",
        "        x[i - 1] = T2[x[i], i]\n",
        "\n",
        "    return x, T1, T2"
      ],
      "metadata": {
        "id": "i7Ov-mWpALky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Computing matrices"
      ],
      "metadata": {
        "id": "hs_Pyx-26GEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.ones((len(tag_to_num), len(tag_to_num)))\n",
        "B = np.ones((len(tag_to_num), len(word_to_num)))\n",
        "Pi = np.zeros(len(tag_to_num))\n",
        "\n",
        "for i in range(len(tags)):\n",
        "    if i == 0 or tags[i - 1] == '.':\n",
        "        Pi[tag_to_num[tags[i]]] += 1\n",
        "\n",
        "    B[tag_to_num[tags[i]]][word_to_num[words[i]]] += 1\n",
        "\n",
        "    if i != len(tags) - 1:\n",
        "        A[tag_to_num[tags[i]]][tag_to_num[tags[i + 1]]] += 1\n",
        "\n",
        "for i in range(len(tag_to_num)):\n",
        "    A[i] /= A[i].sum()\n",
        "    B[i] /= B[i].sum()\n",
        "\n",
        "Pi /= Pi.sum()"
      ],
      "metadata": {
        "id": "DdcSnV9o-xur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pretesting the model"
      ],
      "metadata": {
        "id": "9MMYM86v6MN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K39Tz91zloHB",
        "outputId": "285f0e85-87aa-463e-e99d-680c7ce933fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag, word_tokenize\n",
        "\n",
        "def attempt(_sent, A, B, Pi, _print_end=True, _to_print=False):\n",
        "    sent = []\n",
        "    sent_words = []\n",
        "\n",
        "    for word in word_tokenize(_sent):\n",
        "        sent.append(word_to_num[word])\n",
        "        sent_words.append(word)\n",
        "\n",
        "    sent = np.array(sent)\n",
        "    x, t1, t2 = viterbi(sent, A, B, Pi)\n",
        "\n",
        "    correct = 0\n",
        "    all = 0\n",
        "\n",
        "    correct_answer = pos_tag(word_tokenize(_sent))\n",
        "    for y_pred, y_test in zip(x, correct_answer):\n",
        "        if y_pred == tag_to_num[y_test[1]]:\n",
        "            correct += 1\n",
        "        all += 1\n",
        "\n",
        "    if _to_print:\n",
        "        print('Prediction:\\n  ', end='')\n",
        "        for i, num in enumerate(x):\n",
        "            print(f\"('{sent_words[i]}', '{num_to_tag[num]}')\", end=' ')\n",
        "\n",
        "        print('\\nCorrect answer:\\n  ', end='')\n",
        "        print(*pos_tag(word_tokenize(_sent)), end='\\n\\n' if _print_end else '\\n')\n",
        "\n",
        "    return correct * 100. / all\n",
        "\n",
        "\n",
        "def multiple_attempts(_sents, A, B, Pi):\n",
        "    total_accuracy = 0\n",
        "    total_attempts = 0\n",
        "\n",
        "    for i, _sent in enumerate(_sents):\n",
        "        total_accuracy += attempt(_sent, A, B, Pi, i != len(_sents) - 1)\n",
        "        total_attempts += 1\n",
        "\n",
        "    return total_accuracy / total_attempts"
      ],
      "metadata": {
        "id": "dTNKFbvh0JMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag, word_tokenize\n",
        "\n",
        "sents = ['This is bad phone', 'There is a rain outside', 'This country is a home to many animals']\n",
        "multiple_attempts(sents, A, B, Pi)"
      ],
      "metadata": {
        "id": "kjD9QvH6HItM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31a770ef-4fb2-4878-d015-7dadc1df62de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100.0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM for POS Tagging"
      ],
      "metadata": {
        "id": "vLRfCS58h2cJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data preparation"
      ],
      "metadata": {
        "id": "Qp4zcKZK6a5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "tags_lstm = set()\n",
        "words_lstm = set()\n",
        "tagged_sentences_lstm = [[]]\n",
        "\n",
        "for line in open('train_pos.txt', 'r').readlines():\n",
        "    vals = tuple(line.strip().split())\n",
        "    try:\n",
        "        words_lstm.add(vals[0])\n",
        "        tags_lstm.add(vals[1])\n",
        "        tagged_sentences_lstm[-1].append(vals)\n",
        "        if vals[0] == '.':\n",
        "            tagged_sentences_lstm.append([])\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "tagged_sentences_lstm.pop()"
      ],
      "metadata": {
        "id": "gnd_YXO_3ITg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6b4da12-fc5b-450d-d4a2-6ca5884b207d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "test_sentences_lstm = [[]]\n",
        "\n",
        "for line in open('test_pos.txt', 'r').readlines():\n",
        "    if not line.strip():\n",
        "        continue\n",
        "\n",
        "    vals = tuple(line.strip().split())\n",
        "    try:\n",
        "        test_sentences_lstm[-1].append(vals)\n",
        "        if vals[0] == '.':\n",
        "            test_sentences_lstm.append([])\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "test_sentences_lstm.pop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAj9D5Lx2rcq",
        "outputId": "a622dc05-65b4-40d7-f40a-5e5375feefd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Map tag to some number\n",
        "tag_to_num_lstm = {}\n",
        "for tag in tags:\n",
        "    if tag not in tag_to_num_lstm:\n",
        "        tag_to_num_lstm[tag] = len(tag_to_num_lstm)\n",
        "\n",
        "# Map word to some number\n",
        "word_to_num_lstm = {}\n",
        "for word in words:\n",
        "    if word not in word_to_num_lstm:\n",
        "        word_to_num_lstm[word] = len(word_to_num_lstm)"
      ],
      "metadata": {
        "id": "MWbkB0mR2sjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
        "vocab.update(word_to_num_lstm)\n",
        "\n",
        "tags_vocab = {\"<PAD>\": 0}\n",
        "tags_vocab.update(tag_to_num_lstm)"
      ],
      "metadata": {
        "id": "Vcqsz0MEDuZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_sentences_lstm[0][:3], test_sentences_lstm[0][:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVKvLvg9-HDO",
        "outputId": "18bbf29e-4220-4d81-b171-60f1a937a67a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([('Confidence', 'NN'), ('in', 'IN'), ('the', 'DT')],\n",
              " [('Rockwell', 'NNP'), ('International', 'NNP'), ('Corp.', 'NNP')])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 64\n",
        "SEQUENCE_LENGTH = max([len(L) for L in tagged_sentences_lstm])\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch_input, batch_output = [], []\n",
        "\n",
        "    for sent in batch:\n",
        "        sentence = [x[0] for x in sent]\n",
        "        labels   = [x[1] for x in sent]\n",
        "\n",
        "        if len(sentence) > SEQUENCE_LENGTH:\n",
        "            sentence = sentence[:SEQUENCE_LENGTH]\n",
        "            labels = labels[:SEQUENCE_LENGTH]\n",
        "        elif len(sentence) < SEQUENCE_LENGTH:\n",
        "            sentence.extend(\"<PAD>\" for _ in range(SEQUENCE_LENGTH - len(sentence)))\n",
        "            labels.extend(\"<PAD>\" for _ in range(SEQUENCE_LENGTH - len(labels)))\n",
        "\n",
        "        for i in range(len(sentence)):\n",
        "            sentence[i] = vocab[sentence[i]] if sentence[i] in vocab else vocab['<UNK>']\n",
        "            labels[i] = tags_vocab[labels[i]]\n",
        "\n",
        "        batch_input.append(sentence)\n",
        "        batch_output.append(labels)\n",
        "\n",
        "    batch_input = torch.tensor(batch_input, dtype=torch.long)\n",
        "    batch_output = torch.tensor(batch_output, dtype=torch.long)\n",
        "    return batch_input, batch_output\n",
        "\n",
        "dataloader      = DataLoader(tagged_sentences_lstm, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "test_dataloader = DataLoader(test_sentences_lstm, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "7vTDMsjy4vnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(next(iter(dataloader)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vM2FJFvd5qwC",
        "outputId": "41df4c87-29ce-4455-ecab-282675d52906"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[  977,     2,  2646,  ...,     0,     0,     0],\n",
            "        [ 3527,   263,   281,  ...,     0,     0,     0],\n",
            "        [15605, 15516,    33,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [   94,  1194,    35,  ...,     0,     0,     0],\n",
            "        [  419,   266,    17,  ...,     0,     0,     0],\n",
            "        [  403,   404,   686,  ...,     0,     0,     0]]), tensor([[ 1,  2,  0,  ...,  0,  0,  0],\n",
            "        [18,  9,  4,  ...,  0,  0,  0],\n",
            "        [18,  4, 14,  ...,  0,  0,  0],\n",
            "        ...,\n",
            "        [ 2,  0,  1,  ...,  0,  0,  0],\n",
            "        [ 1, 10, 11,  ...,  0,  0,  0],\n",
            "        [10, 10,  8,  ...,  0,  0,  0]]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_SIZE_TRAIN = len(dataloader.dataset)\n",
        "DATASET_SIZE_TEST = len(test_dataloader.dataset)"
      ],
      "metadata": {
        "id": "rsRVKi7oBxcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LSTM model"
      ],
      "metadata": {
        "id": "-8jFzPIf6hId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "class LSTMTagger(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            embedding_dim,\n",
        "            hidden_dim,\n",
        "            batch_first=True,\n",
        "            num_layers=2,\n",
        "            bidirectional=True\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "        self.hidden2tag = nn.Linear(hidden_dim * 2, tagset_size)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        embeds = self.dropout(embeds)\n",
        "        lstm_out, _ = self.lstm(embeds)\n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "        tag_space = self.hidden2tag(lstm_out)\n",
        "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "        return tag_scores"
      ],
      "metadata": {
        "id": "Hii0AItCD7r1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 512\n",
        "HIDDEN_DIM = 512\n",
        "VOCAB_SIZE = len(vocab)\n",
        "TARGET_SIZE = SEQUENCE_LENGTH"
      ],
      "metadata": {
        "id": "ql9W2cTDHBD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE, TARGET_SIZE)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "l7wOQRn-ExTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training and testing the model"
      ],
      "metadata": {
        "id": "hralSh9p6nv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_calculator(preds, y):\n",
        "    return (preds == y).sum() / (y.shape[0] * y.shape[1])\n",
        "\n",
        "def train(model, dataloader, optimizer, criterion, device):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for text, label in dataloader:\n",
        "        text = text.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        predictions = model(text)\n",
        "        loss = criterion(predictions, label)\n",
        "\n",
        "        acc = accuracy_calculator(\n",
        "            torch.argmax(predictions, dim=1), label\n",
        "        )\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item() * label.shape[0]\n",
        "        epoch_acc += acc.item() * label.shape[0]\n",
        "\n",
        "    return epoch_loss / DATASET_SIZE_TRAIN, epoch_acc / DATASET_SIZE_TRAIN"
      ],
      "metadata": {
        "id": "fX7UEze5FUjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, data_batches, criterion, device):\n",
        "    eval_loss = 0\n",
        "    eval_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for text, tags in data_batches:\n",
        "\n",
        "            tags = tags.type(torch.LongTensor)\n",
        "\n",
        "            text = text.to(device)\n",
        "            tags = tags.to(device)\n",
        "\n",
        "            predictions = model(text)\n",
        "\n",
        "            loss = criterion(predictions, tags)\n",
        "\n",
        "            acc = accuracy_calculator(\n",
        "                torch.argmax(predictions, dim=1), tags\n",
        "            )\n",
        "\n",
        "            eval_loss += loss.item() * tags.shape[0]\n",
        "            eval_acc += acc.item()  * tags.shape[0]\n",
        "\n",
        "    return eval_loss / DATASET_SIZE_TEST, eval_acc / DATASET_SIZE_TEST"
      ],
      "metadata": {
        "id": "D1c_6VDnMQ-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model with the most optimal hyperparameters and layer structure found"
      ],
      "metadata": {
        "id": "NVw0Bx6JUh0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_acc = train(model, dataloader, optimizer, criterion, device)\n",
        "    test_loss, test_acc = evaluate_model(model, test_dataloader, criterion, device)\n",
        "    print(f'Epoch: {epoch+1}, Train [Loss:  {train_loss:.3f}  Acc: {train_acc*100:.2f}, Test_Acc: {test_acc*100.:.2f}]')"
      ],
      "metadata": {
        "id": "FuYRk0KWMS4w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d64dc6f7-e20d-453e-8633-8124943bfa95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Train [Loss:  0.873  Acc: 81.00, Test_Acc: 83.37]\n",
            "Epoch: 2, Train [Loss:  0.609  Acc: 83.54, Test_Acc: 83.60]\n",
            "Epoch: 3, Train [Loss:  0.574  Acc: 83.96, Test_Acc: 84.06]\n",
            "Epoch: 4, Train [Loss:  0.539  Acc: 84.57, Test_Acc: 84.60]\n",
            "Epoch: 5, Train [Loss:  0.504  Acc: 85.29, Test_Acc: 84.95]\n",
            "Epoch: 6, Train [Loss:  0.475  Acc: 85.96, Test_Acc: 85.66]\n",
            "Epoch: 7, Train [Loss:  0.445  Acc: 86.65, Test_Acc: 86.13]\n",
            "Epoch: 8, Train [Loss:  0.415  Acc: 87.37, Test_Acc: 86.28]\n",
            "Epoch: 9, Train [Loss:  0.384  Acc: 88.20, Test_Acc: 86.75]\n",
            "Epoch: 10, Train [Loss:  0.356  Acc: 88.94, Test_Acc: 87.02]\n",
            "Epoch: 11, Train [Loss:  0.323  Acc: 89.86, Test_Acc: 87.40]\n",
            "Epoch: 12, Train [Loss:  0.290  Acc: 90.83, Test_Acc: 87.75]\n",
            "Epoch: 13, Train [Loss:  0.259  Acc: 91.79, Test_Acc: 88.00]\n",
            "Epoch: 14, Train [Loss:  0.231  Acc: 92.65, Test_Acc: 88.08]\n",
            "Epoch: 15, Train [Loss:  0.204  Acc: 93.52, Test_Acc: 88.17]\n",
            "Epoch: 16, Train [Loss:  0.183  Acc: 94.20, Test_Acc: 88.26]\n",
            "Epoch: 17, Train [Loss:  0.159  Acc: 94.96, Test_Acc: 88.38]\n",
            "Epoch: 18, Train [Loss:  0.140  Acc: 95.60, Test_Acc: 88.29]\n",
            "Epoch: 19, Train [Loss:  0.123  Acc: 96.16, Test_Acc: 88.48]\n",
            "Epoch: 20, Train [Loss:  0.110  Acc: 96.61, Test_Acc: 88.46]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "Kz6e0Irkd6z0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluating HMM"
      ],
      "metadata": {
        "id": "g-V-eVDZ6Rsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def multiple_test(_sents, A, B, Pi):\n",
        "    correct = 0\n",
        "    all = 0\n",
        "\n",
        "    for i, sent in enumerate(_sents):\n",
        "        sent_words = []\n",
        "        sent_tags = []\n",
        "        for x in sent:\n",
        "            if x[0] not in word_to_num:\n",
        "                x = (\"<UNK>\", x[1])\n",
        "\n",
        "            sent_words.append(word_to_num[x[0]])\n",
        "            sent_tags.append(tag_to_num[x[1]])\n",
        "\n",
        "        x, t1, t2 = viterbi(sent_words, A, B, Pi)\n",
        "\n",
        "        correct += np.sum(x == sent_tags)\n",
        "        all += len(x)\n",
        "\n",
        "    return correct * 100. / all"
      ],
      "metadata": {
        "id": "uFnDXcFWEexO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hmm_acc = multiple_test(test_sentences, A, B, Pi)\n",
        "print(f'Accuracy of HMM on test data: {hmm_acc:.2f}%')"
      ],
      "metadata": {
        "id": "rjtAhbTrEexP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a7d7288-c15b-4660-ea4f-b14cdb6e2495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of HMM on test data: 89.44%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluating LSTM"
      ],
      "metadata": {
        "id": "-V2p3T-Q6Tej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = evaluate_model(model, test_dataloader, criterion, device)\n",
        "print(f'Accuracy of LSTM on test data: {test_acc*100:.2f}%')"
      ],
      "metadata": {
        "id": "la6BY4HXr0oq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0af3eae0-fe9c-4906-fd6b-37344e2e6326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of LSTM on test data: 88.46%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Printing samples where HMM made mistake"
      ],
      "metadata": {
        "id": "8yY5yIDocn8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_to_word = {j: i for i, j in word_to_num.items()}\n",
        "num_to_tag = {j: i for i, j in tag_to_num.items()}"
      ],
      "metadata": {
        "id": "ztOi0jvXdlbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_mistakes_hmm(_sents, A, B, Pi):\n",
        "    mistakes = []\n",
        "\n",
        "    for i, sent in enumerate(_sents):\n",
        "        sent_words = []\n",
        "        sent_tags = []\n",
        "        for x in sent:\n",
        "            if x[0] not in word_to_num:\n",
        "                x = (\"<UNK>\", x[1])\n",
        "\n",
        "            sent_words.append(word_to_num[x[0]])\n",
        "            sent_tags.append(tag_to_num[x[1]])\n",
        "\n",
        "        x, t1, t2 = viterbi(sent_words, A, B, Pi)\n",
        "\n",
        "        for word, pred, true in zip(sent, x, sent_tags):\n",
        "            if pred != true:\n",
        "                mistakes.append((word[0], num_to_tag[pred], num_to_tag[true]))\n",
        "\n",
        "        if len(mistakes) > 10:\n",
        "            break\n",
        "\n",
        "    return mistakes"
      ],
      "metadata": {
        "id": "qyM5B8j4dbUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mistakes = find_mistakes_hmm(test_sentences, A, B, Pi)"
      ],
      "metadata": {
        "id": "_XATm8sVdbUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Word                   Predicted label         True label       In Train')\n",
        "print(f'------------------------------------------------------------------------')\n",
        "for word, predicted, true in mistakes[:10]:\n",
        "    print(f'{word:<28} {predicted:<20} {true:<15} {word in word_to_num}')"
      ],
      "metadata": {
        "id": "9SUBjVJpfdPf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfce0057-64ee-45ca-9fc5-838a1b4b3644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                   Predicted label         True label       In Train\n",
            "------------------------------------------------------------------------\n",
            "Tulsa                        JJ                   NNP             True\n",
            "extending                    IN                   VBG             False\n",
            "747                          JJ                   CD              True\n",
            "jetliners                    NN                   NNS             False\n",
            "Rockwell                     PRP                  NNP             False\n",
            "calls                        NNS                  VBZ             True\n",
            "supply                       $                    VB              True\n",
            "shipsets                     NN                   NNS             False\n",
            "include                      NN                   VBP             True\n",
            "bulkheads                    NN                   NNS             False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Printing samples where LSTM made mistakes"
      ],
      "metadata": {
        "id": "fLzWBrdmYclQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inv_vocab = {j: i for i, j in vocab.items()}\n",
        "inv_tags_vocab = {j: i for i, j in tags_vocab.items()}"
      ],
      "metadata": {
        "id": "-PpIprRtZrcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_mistakes(model, data_batches, criterion, device):\n",
        "    model.eval()\n",
        "\n",
        "    mistakes = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for text, tags in data_batches:\n",
        "            tags = tags.type(torch.LongTensor)\n",
        "\n",
        "            text = text.to(device)\n",
        "            tags = tags.to(device)\n",
        "\n",
        "            predictions = model(text)\n",
        "\n",
        "            loss = criterion(predictions, tags)\n",
        "\n",
        "            acc = accuracy_calculator(\n",
        "                torch.argmax(predictions, dim=1), tags\n",
        "            )\n",
        "\n",
        "            pred = torch.argmax(predictions, dim=1).cpu().detach().numpy()\n",
        "            true = tags.cpu().detach().numpy()\n",
        "            word = text.cpu().detach().numpy()\n",
        "\n",
        "            for pred_i, true_i, words_i in zip(pred, true, word):\n",
        "                for i in range(len(pred_i)):\n",
        "                    if pred_i[i] != true_i[i]:\n",
        "                        mistakes.append((words_i[i], pred_i[i], true_i[i]))\n",
        "                        break\n",
        "\n",
        "            if len(mistakes) >= 10:\n",
        "                break\n",
        "\n",
        "    return mistakes"
      ],
      "metadata": {
        "id": "UO_q__1UYf3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mistakes = find_mistakes(model, test_dataloader, criterion, device)"
      ],
      "metadata": {
        "id": "pmFc2dbyY3rJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Word                   Predicted label         True label       In Train')\n",
        "print(f'------------------------------------------------------------------------')\n",
        "for word, predicted, true in mistakes[:10]:\n",
        "    print(f'{inv_vocab[word]:<28} {inv_tags_vocab[predicted]:<20} {inv_tags_vocab[true]:<15} {word in vocab}')"
      ],
      "metadata": {
        "id": "v7rWlNA_ahc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f99eb405-3247-4c37-b85f-691b884fc4f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                   Predicted label         True label       In Train\n",
            "------------------------------------------------------------------------\n",
            "in                           IN                   NNP             False\n",
            "unexpectedly                 NN                   RB              False\n",
            "latest                       NN                   JJS             False\n",
            ",                            POS                  ,               False\n",
            "Small-business               IN                   NN              False\n",
            "prices                       VBD                  NNS             False\n",
            "was                          NN                   VBD             False\n",
            "although                     ,                    IN              False\n",
            "often                        VBZ                  RB              False\n",
            ".                            VBN                  .               False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "95HCITItd9W5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "HMM:\n",
        "* Matrices computation and prediction are fast (computation <1s, prediction ~2s)\n",
        "* The resulting accuracy on test dataset is **89.44%**\n",
        "* HMM sometimes makes mistakes in the words that it did not see yet (explained in the pros and cons part)\n",
        "\n",
        "LSTM:\n",
        "* Training takes 6 minutes (for the hyperparameters that I chose in the end)\n",
        "* The resulting accuracy on test dataset is **88.14%**\n",
        "* LSTM mostly makes mistakes in the words that it did not see before (which receive an \\<UNK\\> tag during testing)"
      ],
      "metadata": {
        "id": "MCtmHXRQ01B1"
      }
    }
  ]
}